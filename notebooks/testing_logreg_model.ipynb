{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbd5b54",
   "metadata": {},
   "source": [
    "# Тест логрег модели + понимание где она ошибается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4e5bc",
   "metadata": {},
   "source": [
    "## Прогон кода и предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d51e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, concat\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import datetime\n",
    "from stop_words import get_stop_words\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "from json import load as json_load\n",
    "from numpy import int64, array, logspace, isnan, isfinite, nan_to_num, empty, zeros\n",
    "from joblib import Parallel, delayed\n",
    "from tabulate import tabulate\n",
    "from pickle import load as pickle_load\n",
    "from typing import List, Union\n",
    "from sklearn.base import RegressorMixin, TransformerMixin\n",
    "from transliterate import translit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778342cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_model_loader(path: str) -> Union[RegressorMixin, TransformerMixin]:\n",
    "    \"\"\"Load your model from pickle. Might be insecure.\"\"\"\n",
    "    with open(path, 'rb') as model_file:\n",
    "        return pickle_load(model_file)\n",
    "\n",
    "\n",
    "def safe_json_loader(path: str) -> dict:\n",
    "    \"\"\"Load your dict from JSON.\"\"\"\n",
    "    with open(path, 'rb') as model_file:\n",
    "        return json_load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1964dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = \"../lib/logreg_models/\"\n",
    "\n",
    "tf_idf = pickle_model_loader(path_to_models + \"text_transformer.pickle\")\n",
    "dict_vectorizer = pickle_model_loader(path_to_models + \"cat_transformer.pickle\")\n",
    "logreg = pickle_model_loader(path_to_models + \"logreg.pickle\")\n",
    "regexp_dict = safe_json_loader(path_to_models + \"regexps/regexp.json\")\n",
    "\n",
    "logreg.n_jobs = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef03877",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['subcategory', 'category', 'region', 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74b26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regexp_transformer(series, regexps: dict):\n",
    "    \"\"\"Find the presence of regexps in your Series.\"\"\"\n",
    "    columns = empty((len(regexps), len(series)), dtype=int)\n",
    "    for index, (_, regexp) in enumerate(regexps.items()):\n",
    "        columns[index] = series.str.contains(regexp).astype(int).values\n",
    "    return columns.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9565b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/integrant/.local/lib/python3.8/site-packages/pandas/core/strings/accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.49 s, sys: 23.8 ms, total: 8.51 s\n",
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataframe = read_csv(\"../data/val.csv\")\n",
    "description = dataframe.description.replace(r'[\\W_]+', ' ', regex=True).str.lower()\n",
    "\n",
    "tf_idf_result = tf_idf.transform(description)\n",
    "dict_vectorizer_result = dict_vectorizer.transform(dataframe[categories].to_dict('records'))\n",
    "regexp_result = regexp_transformer(description, regexp_dict)\n",
    "\n",
    "features = hstack([tf_idf_result, dict_vectorizer_result, regexp_result], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b4f15f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_printer(predictions, labels, model: RegressorMixin) -> None:\n",
    "    \"\"\"Print your model's AUC.\"\"\"\n",
    "    headers = ['Model', 'Metric', 'Value']\n",
    "    table = []\n",
    "    model_name = type(model).__name__\n",
    "    roc_auc = roc_auc_score(labels, predictions)\n",
    "    table.append([model_name, 'AUC', roc_auc])\n",
    "    print(tabulate(table, headers=headers, tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4105af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict_proba(features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_printer(predictions, dataframe[\"is_bad\"].values, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033dd6f",
   "metadata": {},
   "source": [
    "## Тут я тырил новые регулярки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fec2943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Продам действующий бизнес. Магазин-бар разливных напитков. Расположен в отдельно стоящем здании. Ассортимент разливных напитков более 10 видов, более 400 видов снеков и закусок. Установлено видеонаблюдение, телевизор, холодильное оборудование, кондиционер, большой кегератор. Возможно работать 21/7. Рассмотрим все предложения(доп.тел.8.9.4.1.8.9.7.1.5.5.1)',\n",
       "       'Продам готовый отлаженный бизнес.Магазин-бар разливных напитков. Постоянные клиенты, база поставщиков, выгодное расположение. Более 50 видов разливных напитков. Большой кегератор. Установлена система видео наблюдения. Интернет, телевизор.Расмотрим все варианты(доп.тел.8.9.2.5.8.9.7.5.1.1.5)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[(dataframe[\"is_bad\"] == 1) & (dataframe[\"category\"] == \"Для бизнеса\")].description.iloc[0:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "283d55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "77f8930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247      Сдам квартиру семейным людям,8969 создающие611...\n",
       "318      ￼Спортивные покрытия. От 190 рублейПроизводите...\n",
       "321      Продам участок 54,27 сот., земли поселений (ИЖ...\n",
       "328      Холодильник-морозильник Стинол-404, двухкамерн...\n",
       "430      Набор BoxMezone CyberSport – это не просто игр...\n",
       "                               ...                        \n",
       "15872    Имеется коррозия на крыльях!8 Все узлы, агрега...\n",
       "15971    Утюг электрический IR-4463 /\\n /\\nВас приветст...\n",
       "16105    Предлагается 2-х комнатная квартира с изолиров...\n",
       "16152         На 922ходу,222продаю 2050с номерами в593ор77\n",
       "16225    Минимойка Xiaomi Kärcher K1 FM Cordless/\\n /\\n...\n",
       "Name: description, Length: 268, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[(dataframe[\"predictions\"] < 0.1) & (dataframe[\"is_bad\"] == 1)].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe0b14",
   "metadata": {},
   "source": [
    "## Тут я решил обучить предикторы внутри каждой из категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b76ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Транспорт', 'Для бизнеса', 'Для дома и дачи', 'Личные вещи',\n",
       "       'Услуги', 'Бытовая электроника', 'Недвижимость', 'Хобби и отдых',\n",
       "       'Работа', 'Животные'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e809c5a",
   "metadata": {},
   "source": [
    "Собственно я их обучил, тут я тестирую пайплайн для работы с тестом и поменяю конечный файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c72317b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = list((category, translit(category.lower().replace(\" \", \"_\"), 'ru', reversed=True)) for category in dataframe[\"category\"].unique())\n",
    "logregs = {}\n",
    "for category, name in cat_names:\n",
    "    with open(\"../lib/logreg_models/{0}.pickle\".format(name), 'rb') as file:\n",
    "        if file:\n",
    "            logregs[category] = pickle_load(file)\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b524925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_fitter(df_train, Model, params, X_train, y_train):\n",
    "    models = {}\n",
    "    for category in df_train[\"category\"].unique():\n",
    "        start = timer()\n",
    "        print(\"Now working on '{0}' category.\".format(category))\n",
    "        if params:\n",
    "            model = Model(**params[category])\n",
    "        else:\n",
    "            model = Model()\n",
    "        model.fit(X_train[df_train[\"category\"] == category], y_train[df_train[\"category\"] == category])\n",
    "        models[category] = model\n",
    "        print(\"Category {0} finished, elapsed time: {1:.1f}s.\\n\".format(category, timer() - start))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de53fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_printer(features, labels, models, dataframe, models_class):\n",
    "    overall_table = []\n",
    "    cats_table = []\n",
    "    labels_pred = zeros(labels.shape)\n",
    "    for category in dataframe[\"category\"].unique():\n",
    "        cat_name = translit(category.lower().replace(\" \", \"_\"), 'ru', reversed=True)\n",
    "        model = models[category]\n",
    "        labels_pred[dataframe[\"category\"] == category] = model.predict_proba(features[dataframe[\"category\"] == category])[:, 1]\n",
    "        rocauc_category = roc_auc_score(labels[dataframe[\"category\"] == category], labels_pred[dataframe[\"category\"] == category])\n",
    "        cats_table.append([cat_name, rocauc_category])\n",
    "    rocauc = roc_auc_score(labels, labels_pred)\n",
    "    overall_table.append([models_class, rocauc])\n",
    "    print(\"Categories table:\")\n",
    "    print(tabulate(cats_table, headers=[\"Category\", \"AUC\"], tablefmt='orgtbl'))\n",
    "    print(\" _____________________________________________\")\n",
    "    print(\".____________________________________________.>\")\n",
    "    print(\"Overall table:\")\n",
    "    print(tabulate(overall_table, headers=['Model', 'AUC'], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ca94e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories table:\n",
      "| Category             |      AUC |\n",
      "|----------------------+----------|\n",
      "| transport            | 0.981164 |\n",
      "| dlja_biznesa         | 0.922197 |\n",
      "| dlja_doma_i_dachi    | 0.915825 |\n",
      "| lichnye_veschi       | 0.813546 |\n",
      "| uslugi               | 0.848407 |\n",
      "| bytovaja_elektronika | 0.929878 |\n",
      "| nedvizhimost'        | 0.954078 |\n",
      "| hobbi_i_otdyh        | 0.87889  |\n",
      "| rabota               | 0.879812 |\n",
      "| zhivotnye            | 0.866757 |\n",
      " _____________________________________________\n",
      ".____________________________________________.>\n",
      "Overall table:\n",
      "| Model   |      AUC |\n",
      "|---------+----------|\n",
      "| logreg  | 0.948752 |\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(features, dataframe[\"is_bad\"].values, logregs, dataframe, \"logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd59168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
